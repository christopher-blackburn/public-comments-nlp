 1. What are the main challenges faced by national, state/provincial, or local governments that are trying to build a basis for evidence-based policy? Briefly describe the bottlenecks and pain-points they face in the evidence-based decision-making process.  Quasi-experimental designs combine data from federal, state and local programs with “universe” datasets, such as the business or household/person frames, need to navigate a complex set of agency norms and administrative and legal hurdles in order to share data.  While the Evidence Act encourages agencies to conduct evidence building activities, it is still very difficult to navigate this process.  Advancements in machine learning and computing power, coupled with the proliferation of third-party data have transformed the landscape of data protection. Statistical disclosure limitation methods that have been used for decades to protect confidentiality are increasingly vulnerable to sophisticated database reconstruction and reidentification attacks. Many government agencies at the federal, state, and local levels are unaware of the seriousness of these new threats, lack staff capable of performing sophisticated, quantifiable assessments of these new disclosure risks, and lack the resources to effectively invest in the design and implementation of new statistical disclosure limitation methods (and tiered data access mechanisms) to address these challenges.   2. What are examples of high-impact data uses for evidence-based policy making that successfully effected change, reduced costs, or improved the welfare of citizens?  Quasi experimental studies of programs that provide causal estimates of program effectiveness are a cost-effective method for evidence building, but many of the public data products produced by Census help federal, state and local officials make more informed decisions.  A recent example, Census supplied demographic and economic data to HHS/CDC to help guide decision making for COVID-19 response and recovery and data was supplied on language spoken at home so COVID-19 informational materials could be produced in the common language for that area.   3. Which frameworks, policies, practices, or methods show promise in overcoming challenges experienced by governments in their evidence building?   Formally private methods for statistical disclosure limitation (e.g., Differential Privacy) show significant promise for countering the growing risk of re-identification. The quantification of privacy risk inherent to these methods allows for precise tuning of the privacy vs. accuracy tradeoff inherent to disclosure avoidance implementations, and the "future-proof" nature of these protections permits a "release-and-forget" approach to data dissemination that is not possible with most other techniques.     New techniques for generating synthetic data, particularly when coupled with verification or validation servers, show great promise for expanding the availability of high-quality data for evidence-building at low privacy cost.  Advancements in secure multiparty computation show promise in enabling sophisticated linkage and analysis without exposing the underlying confidential data.  When coupled with automated and robust statistical disclosure limitation techniques, this technology could greatly expand the use of confidential data for evidence-building and completely bypasses many of the impediments to data sharing described above.  Also, interagency working groups for Emergency Management have shown promise by the better communication, coordination, and the exchange of data.  Census has used its COVID-19 Interactive Data Hub to link to 38 COVID related datasets for state, local, tribal, territorial (SLTT), and public use. Prior to Census taking this action, these datasets were not all in one place and available to SLTT and the public.   4. The Commission on Evidence-Based Policymaking (See: www.cep.gov) recommended the creation of a National Secure Data Service (See Commission Report at www.cep.gov). Do you agree with this recommendation, and if so, what should be the essential features of a National Secure Data Service?  Many government agencies lack the human capital and financial resources to maintain a robust and effective data protection and data dissemination program. The availability of a National Secure Data Service, which could support data protection and data dissemination activities "as a service" for federal, state, or local governments, could benefit from obvious economies of scale to enable greater dissemination of data with stronger privacy protections.  Also, a secure data service needs to offer:  • A centralized hashed person/business linking capability similar to our PIK process. The best way to do that would be to base it off of something like the SSA Numident.  • A comprehensive inventory of data available in the NSDS. • The service should provide scalable multi-functional infrastructure that is either fully  funded or offers full cost recovery for the government. • An even better solution we can work toward would be to create a secure multiparty  computing infrastructure to allow agencies to contribute data for analysis without actually relinquishing control of those data.  • The data service should also provide internal expertise on the availability, composition, and limitations of the data offerings.  • The NSDS should manage a centralized data sharing agreement process rather than leveraging the patchwork of agreements that are currently in place at the individual agencies.       5. How can federal agencies protect individual and organizational privacy when using data for evidence building? Recommend specific actions the Office of Management and Budget and/or other federal agencies can take when using data for evidence building, as well as suggested changes to federal laws, policies, and procedures.  Many agencies data assets are protected by statutes which prohibit the release of any identifiable information. That said, no statistical disclosure limitation technique or tiered access mechanism is 100% effective at eliminating disclosure risk. The release of any information, no matter how well protected, carries a non-negligible risk of disclosure. Consequently, agencies have to approach this from a risk assessment and risk mitigation perspective, but there is little statutory or policy guidance on how much risk is acceptable. Clear legal frameworks for defining acceptable risk would clarify the extent of the privacy guarantees we are expected to uphold while helping agencies to make more data available for evidence-building.  Securing data and still making it accessible to users is critical. Using Protected Identification Keys (PIKs) as Census does is important. As well as utilizing secure environments that already exists like the Federal Statistical Research Data Centers (FSRDCs) - Secure Data Access.   A law should be passed containing "data used for evidence building under this law and with the controls laid out herein satisfy all of the confidentiality and use restrictions present in Title 13 U.S.C., CIPSEA, Title 26, and program agency specific statutory and regulatory use restrictions, and privacy act routine uses for evidence building, etc.” Without this piece, a tremendous amount of staff time and bandwidth may be spent trying to reconcile these legal conflicts and such a measure would break down any silos between agencies.  It is going to be extremely difficult for this to happen though under an existing framework, such as our FSRDC process, under current statutes and regulations. It shouldn't fall to one agency to negotiate terms with all of the others to allow their data to be provisioned and used in this way. This should come from OMB.  Another key piece is having some federally-recognized accreditation process for Disclosure Review. This would be similar to the registration process for Institutional Review Boards (IRB). That way we know everyone is meeting a minimum standard when they're reviewing output for disclosure limitation.   6. If created, how should a data service be structured to best facilitate (1) research and development of secure data access and confidentiality technologies and methods, (2) and agency adoption of those technologies and techniques?  A data service needs to conform with existing laws concerning data sharing and privacy    such as Title 13, Title 15 and Title 26, or these laws need to be modified.   7. Government agencies have argued that secure data access has value because it (1) improves service delivery, (2) improves efficiency (lowers costs), (3) produces metrics for performance measurement, and (4) produces new learnings/insights from the data. Which of these propositions do you agree holds value and why? Do you have examples that demonstrate these benefits? Do you have other examples of the value of secure data access?  They all hold value and are essential to successful secure data access and impactful outcomes.  (Data Services to Federal, State, Local Agencies and the Public.)    Data service needs to conform with existing laws concerning data sharing and privacy such as Title 13, Title 15 and Title 26, or these laws need to be modified.   8. What are the most pressing data needs of state and local decision makers and how would making data accessible from federal agencies help meet those needs? To share data, what guarantees do data owners (or data controllers) need regarding privacy, data stewardship, and retention?  SLTT data access is vital. The most pressing need is geographic granularity. Data at the State level isn’t very useful to local governments. Minimum county and lower data is crucial for something to be actionable. Additionally, the more recent the data the better. Weekly Small Business Pulse, Weekly Household Pulse and Weekly Business Formation Statistics are three examples of Census programs with timely recent data about the impacts of COVID-19.  Data service needs to conform with existing laws concerning data sharing and privacy such as Title 13, Title 15 and Title 26, or these laws need to be modified.   9. What are the key problems and use cases where collaborative work between federal, state, and local authorities' data analysis can inform decisions? What are key decision support tools? How would greater communication about data and tools benefit expanded evidence building?  Census Bureau’s Emergency Preparedness and Response Team (EPRT) delivers key demographic and economic data to FEMA and other agencies to help them in preparedness, response, and recovery efforts when disasters strike. Census produces an Emergency Management page for access to this data by anyone that needs it. Census has also made available easy to use tools to deliver this data.   10. What basic public data services are essential for a data service to address existing capacity gaps and needs? What infrastructure or incentives can the federal government create that locals and states cannot?      The Census Bureau’s Post-Secondary Employment Outcomes (PSEO) is a great example of how the federal government can provide a service that individual states or consortiums of states cannot.  Many states (Texas, for example) produce statistics similar to PSEO, but many graduates leave the state for work.  These individuals’ wage records exist in other state datasets and are most likely unobserved to Texas (there are sometimes states that share data with other states in their region).  The LEHD program at the Census Bureau, which has the wage records from most states, can produce statistics for most graduates, not just the ones that remain in Texas.  PSEO uses formal privacy protection methods because of these closely related statistics, but this does raise the issue of how to manage privacy “budgets” for multi-agency data.  