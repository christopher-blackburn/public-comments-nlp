   January 20, 2021    Advisory Committee on Data for Evidence Building  4600 Silver Hill Road  Washington, DC 20233   Re: Response to General Questions 1, 2, 3, 4, 8, 9 and 10 for the Advisory Committee on   Data for Evidence-Building (Dockment # 2020-27489)   Dear Committee Members:   Results for America (RFA) appreciates the opportunity to provide comments on the challenges  faced and best practices adopted at the federal, state and local level to use data to build  evidence and have attached our responses to questions 1, 2, 3, 4, 8, 9 and 10.    Transparent, robust data access is necessary for federal, state and local leaders to be able to  harness the power of evidence to get better results now while investing in long-term prosperity  and opportunity.   Governments at all three levels, however, are facing challenges related to lack of quality data,  financial resources, and/or technical capacity.    We commend your efforts to identify and address these problems. You should feel free to  contact Kate Tromble at kate@results4america.org with any questions you may have regarding  our comments.    Sincerely,    Michele Jolin    David Medina    Kate Tromble  CEO & CO-Founder   COO & Co-Founder   VP, Federal Policy  Results for America   Results for America   Results for America       2  CENTRAL QUESTIONS  1. What are the main challenges faced by national, state/provincial, or local governments  that are trying to build a basis for evidence-based policy? Briefly describe the  bottlenecks and pain-points they face in the evidence-based decision-making process.  The main challenges faced by local, state, and federal governments trying to develop and  implement evidence-based policy include but are not limited to infrastructure, technical capacity,  funding, and flexibility. The federal government has begun to address the infrastructure issue  through implementation of the Foundations of Evidence-based Policymaking Act (Evidence Act),  which requires specific leadership positions, policies, and strategic planning focused on  developing the basis for policy and budget decisions grounded in evidence.   Some states, as articulated more particularly below, have followed suit and appointed chief data  or performance officers and articulated state or city-wide goals for evidence-based policies. But,  states and cities/counties struggle with enough technical know-how and capacity to fully  implement evidence-based policymaking. Even state agencies that are data rich are often  information poor; they lack sufficient analytical capacity. This is partly tied to not having clear  learning agendas that ensure everyone is using the data they have to ask and answer a  specified set of questions that are of practical interest to leaders and constituents.   The federal government can help by ensuring that federal funding streams for states and cities  include the ability for states and cities to use those dollars to enhance their technical and  analytical capabilities and develop learning agendas as well as to fund particular programs.  Moreover, states and cities could benefit from federal dollars allocated specifically for evaluation  and data capacity development. For instance, many state and local governments are asked to  participate in evaluations but don’t have the necessary expertise to create control groups  because they do not have statistical experience and limited bandwidth beyond administering  their programs. They also suffer from time and resource constraints that make participating in  evaluations or data collections difficult. There is a broader and deeper pool of evaluation, data,  and evidence expertise - as well as funding - available at the federal level. States and  cities/counties know that and welcome the extension of that expertise and funding.  As noted, even when states and cities/counties develop the infrastructure and technical capacity  to implement evidence-based policymaking approaches often the federal resources that fund  their programs (particularly, education, workforce, child welfare and justice programs) are  restrictive in how they can be used. Allowing states and cities flexibility over the use of their  federal funds if they combine state resources and prioritize evidence in the distribution of those  combined funds could incentivize more governments to embrace an evidence-based  policymaking approach. Moreover, offering waivers and flexibility to states and cities that wish to      3  combine funding streams to support innovative interventions and approaches that they  rigorously evaluate would further allow more states and cities to fully embrace an evidence- based policymaking approach.   Finally, data sharing remains a primary pain point for most states. For instance, state workforce  agencies have limited access to state educational data, and no access to federal educational  data such as the National Student Clearinghouse. In addition, state workforce agencies have  limited access to the National Directory of New Hire Data housed at HHS Administration for  Children and Families Office of Child Support Enforcement. In addition, state workforce  agencies have no access to income tax data, which is incredibly important as we see more and  more gig work in the U.S. economy. There is also currently very limited labor market and  workforce information data sharing between states and no common data systems between  states either. Beyond cross-agency data sharing and linking challenges, many state agencies  also suffer from challenges linking data across parts of the same system (e.g., early childhood  system, PK-12 system, and higher education institutions). This makes it even more difficult to  track and measure the impact on investments and/or policies over time.  2. What are examples of high-impact data uses for evidence-based policy making that  successfully effected change, reduced costs, or improved the welfare of citizens?  Through our 2020 Invest in What Works Federal Standard of Excellence, 2020 State Standard  of Excellence, and work with more than 200 cities across the country, RFA has identified the   following examples of high impact data uses at the federal, state and local levels.   ● Federal Examples:  1. Administration for Children and Families’ (ACF)  ■ TANF Data Innovation Project supports cohorts of states to improve the  effectiveness of Temporary Assistance for Needy Families (TANF)  programs by helping them better leverage human services data. This has  helped states enhance data analytics for program improvement and gain  better understanding of issues so that they can strengthen integrated data  systems and improve program integrity and payments.   ■ ACF’s Office of Planning Research and Evaluation’s (OPRE) Human  Services Interoperability Demonstration Grants, help expand data sharing  efforts by state, local, and tribal governments to improve human services  program delivery, and identify novel data sharing approaches that can be  replicated in other jurisdictions.   ■ OPRE, through a partnership with the Office of the Assistant Secretary for  Planning and Evaluation (ASPE), helps states link Medicaid and Child  Welfare data at the parent-child level to support outcomes research.      4  Through this project, OPRE and ASPE work with two to four states to  enhance capacity to examine outcomes for children and parents who are  involved in state child welfare systems and who may have behavioral  health issues. Of particular interest are outcomes for families that may  have substance use disorders, like opioid use disorder. Specifically this  project seeks to develop state data infrastructure and increase the  available de-identified data for research in this area.   2. Department of Housing and Urban Development (HUD):   ■ HUD has created an updated list of open data assets; numerous Policy  Development and Research (PD&R)produced datasets for researchers  and practitioners, including tenant public use microdata samples; and an  eGIS portal providing geo-identified open data to support public analysis  of housing and community development issues using GIS tools.  ■ HUD has implemented data linkage agreements with the National Center  for Health Statistics and the Census Bureau to enhance major national  survey datasets by identifying HUD-assisted households, with updates  continuing in FY20; making available major program demonstration  datasets in secure environments; and producing special open-access  tabulations of census data for HUD’s partners.  ■ HUD’s engagement in cooperative agreements with research  organizations, including both funded Research Partnerships and  unfunded Data License Agreements, supports innovative research that  leverages HUD’s data assets and informs HUD’s policies and programs.  Data licensing protocols ensure that confidential information is protected.  In 2019, HUD expanded the Standards for Success data collection and  reporting framework for discretionary grant programs to cover Resident  Opportunities and Self-Sufficiency Service Coordinator (ROSS) grants,  Multifamily Housing Service Coordinator grants, and Multifamily Housing  Budget-Based Service Coordinator Sites. The framework supports better  outcomes by providing a more standardized performance measurement  framework, better alignment with Departmental strategies, and more  granular reporting to support analytics.    3. Department of Labor:  ■ DOL’s Performance Management Center created a performance  reporting and dashboard system to review each agency’s program  performance, analyze progress, and identify opportunities for  performance improvements. These performance reviews connect to      5  DOL’s broader performance and evaluation activities. DOL’s Office of the  Chief Information Officer (OCIO) developed a new dashboard, the CXO  Dashboard, which provides agency leadership instant access to key  administrative data to access progress and performance and make data- driven decisions.   4. Millennium Challenge Corporation (MCC):   ■ For every investment in implementation, MCC undertakes a Quarterly  Performance Review with senior leadership to review, among many  issues, results indicator tracking tables. If programs are not meeting  evidence-based targets, MCC undertakes mitigation efforts to work with  the partner country and program implementers to achieve desired results.  These efforts are program- and context-specific but can take the form of  increased technical assistance, reallocated funds, and/or new methods of  implementation. For example, in FY20 MCC reallocated funds in its  compact with Ghana after the country failed to achieve agreed-upon  policy reforms to ensure the sustainability of the investments. Upon  program completion, if a program does not meet expected results targets,  MCC works to understand and memorialize why and how this occurred,  beginning with program design, the theory of change, and program  implementation. The results and learning from this inquiry are published  through the country’s Star Report, Monitoring and Evaluation plans, and  tables of key performance indicators.   ● State Examples :  1. States leveraged data to better respond to COVID by connecting and linking  administrative data sets or other existing data sets to ensure continuity of  government services and programs.  ■ The Indiana Management Performance Hub (MPH), overseen by the  state’s Chief Data Officer, houses the integrated Education and  Workforce Development database, which brings together data from 12  state agencies, including: the Commission for Higher Education,  Department of Education, Department of Health, Department of  Corrections, Department of Workforce Development, and Family and  Social Services Administration to answer questions about the education  and workforce pipeline. In addition, MPH has created integrated  databases to address pressing program and policy issues related to  COVID-19, opioids, Medicaid, fiscal transparency, and other areas. MPH  has been at the forefront of using data to drive decision-making for      6  Indiana’s COVID-19 response, including studies to better understand the  prevalence of the coronavirus and/or its antibodies.   ■ The Connecticut Departments of Education and Social Services  leveraged data-sharing agreements by matching student and SNAP  benefit data to automatically certify SNAP Pandemic EBT for more than  287,000 Connecticut students who receive free or reduced-price meals.  This allowed the state to provide meals to 82,000 students participating in  only the National School Lunch Program and School Breakfast Program,  but who do not receive food assistance through SNAP, Medicaid, or other  food assistance programs. The state also partnered with food retailers to  allow SNAP enrollees to use their benefits to purchase eligible food items  online.   ■ Amid the 2020 COVID-19 pandemic, Virginia’s workforce system  launched an improved integrated data system, governed by a data trust,  that improves user experience through the new Virginia Career Works  Referral Portal. The related Virginia Career Works Dashboard is a data  visualization tool that conveys information about labor conditions and  allows agencies to make real-time, data-driven decisions. These  innovative systems demonstrated a potential cost savings of more than  94% over traditional approaches.   ■ In response to the federal COVID-19 Pandemic Unemployment  Assistance program, Rhode Island’s Department of Labor and Training  partnered with the nonprofit Research Improving People’s Lives and  Amazon Web Services to develop a cloud-based system to share data  and improve management of unemployment claims. This enabled Rhode  Island to be among the first states in the nation to provide Pandemic  Unemployment Assistance benefits in the face of record-high employment  claims during the COVID-19 crisis.   2. Even prior to the COVID-19 pandemic, several states were integrating and  linking administrative data across state agencies to improve the impact of their  programs and respond based on insights generated from these integrated  approaches.  ■ A 2013 Kentucky law established the Kentucky Center for Statistics  (KYSTATS), which collects and links high-quality, actionable data from 15  state agencies to improve education and workforce programs in the state.      7  By providing data sets, publishing reports, and fulfilling research requests,  the Center provides state-specific insights with appropriate data privacy  and data access controls. It has more than 40 staff members who are  dedicated to “developing reports, responding to research requests, and  providing statistical data about these efforts so policymakers, agencies,  and the general public can make better-informed decisions.” The Center  is run by an executive director with oversight from a board composed of  participating state agencies, and Center has developed a research  agenda for 2020-2022 focused on issues of equity.   ■ New Jersey’s Prescription Monitoring Program integrates data from  multiple state agencies, including the Department of Health, the Division  of Consumer Affairs, the Office of the Attorney General, and other law  enforcement bodies, to power the Overdose Data Dashboard. The  Department of Health uses the dashboard to make decisions about  access to medications, such as naloxone, designed to rapidly reverse  opioid overdose and harm reduction services.   ■ The Washington Education Research and Data Center’s memorandum of  understanding describes how data will be collected and shared among  partners. It has a strong focus on protecting individual privacy. The  Center gathers 11 partners, including state workforce, education, and  child welfare agencies, to compile education and workforce data to  improve student achievement and workforce outcomes.   ■ The Washington State Department of Social and Health Services  maintains an integrated client database with data from 10 state agencies,  40 separate data systems, and millions of individuals receiving services  through publicly funded health and human services programs in  Washington State. This data is used for rapid-cycle policy analysis,  program evaluation, predictive modeling, and performance measurement  to help agencies understand how health services and other factors are  related to outcomes for persons served by public assistance programs.  Predictive modeling and clinical decision support tools developed and  maintained in the Research and Data Analysis’s integrated data  environment have been used by the state’s Health Home Program, which  provides intensive care management services to high-risk Medicaid  beneficiaries, to improve beneficiary health outcomes and lower costs.  These lower costs have resulted in tens of millions in dollars in shared      8  savings payments from the federal Centers for Medicare and Medicaid  Services.   ● City Examples:   1. Many cities have data-driven performance programs that have led to outcomes  for residents.   ■ City of Tulsa. Tulsa’s CARES program is credited for a 70% reduction in  911 calls from its top 911 utilizers.   ■ City of Detroit - Housing Resource Centers. Utilizing data from the impacts of the  2008 on evictions and foreclosures and how destabilizing this is for families, the  City of Detroit’s Housing and Revitalization Department worked to request that  $1.5 million in CARES Act funding be used to provide additional support to  Housing Resource Centers. The Housing Resource Centers connect low income  residents to housing services which include: providing eviction prevention  services, rental support, home repair, tax and title management services.    The Housing Resource Centers are designing the Housing Resource Center  program in partnership with the city to address acute housing needs, develop  shared program metrics and ultimately improve results for residents through an  integrated service model.    ■ City of Newark - Landlord Registrations. The City of Newark and the City of  Racine wanted to be able to measure and preserve affordable rents for their  residents but did not have a reliable way of gathering this information. Both cities  are working with What Works Cities to increase landlord registrations for their  properties which will help preserve affordable housing and ensure city code  enforcement    ■ City of Lansing - Children Savings Accounts. Using the lessons gained from  their technical assistance with What Works Cities, the City of Lansing played  a key role in informing Michigan’s statewide Children Savings Account  programs administered by the Community Economic Development  Association of Michigan (CEDAM). CEDAM has now begun requesting  performance metrics developed by the City of Lansing in partnership with  What Works Cities partners (GPL and GovEx) on a quarterly basis. Although      9  CEDAM had administered Children Savings Accounts for several years,  impacting over 18,000 students across the state to date, they had never  requested performance metrics from partners before.  3. Which frameworks, policies, practices, or methods show promise in overcoming  challenges experienced by governments in their evidence building?  1. Federal Examples:  ○ Providing resources for evaluation can be helpful in evidence-building. This  comes through direct spending for research and evaluation through budgets or  program set asides. For example, in our 2020 Invest in What Works Federal  Standard of Excellence, nearly half of the nine participating agencies (44%)  reported investing 1% or more of their budgets on evaluation-related activities--  these agencies include: ACL, USAID, CNCS, and MCC. Federal agencies and  departments can also provide technical assistance and support on data  collection, research, and evaluation activities.   ■ Department of Education. The Regional Education Laboratories (RELs)  provide extensive technical assistance on evaluation and support  research partnerships that conduct implementation and impact studies on  education policies and programs in ten geographic regions of the U.S.,  covering all states, territories, and the District of Columbia. Congress  appropriated $55.4 million for the RELs in FY20. Also, IES’s State  Longitudinal Data Systems grants support states in developing their data  share infrastructure as well as their technical capabilities.   ■ Department of Housing and Urban Development. For FY20, HUD is  providing $91 million of technical assistance to equip the Department’s  program partners with the knowledge, skills, tools, capacity, and systems  to implement HUD programs and policies successfully and to provide  effective oversight of federal funding. State and local governments and  authorities are among the eligible applicants, with approximately 23  awards expected. Community Compass integrates technical assistance  funding from four major HUD program areas to better reflect the cross- cutting nature of housing and community development challenges.  Eligible technical assistance activities include training and tool  development to help program partners improve program management,  evaluation, and performance measurement, and the Community  Compass program itself has an increased evidence-based focus for  FY20.      10   ■ AmeriCorps: Research and Evaluation funds a contractor to provide  AmeriCorps grantees with evaluation capacity building support ($500,000  of the $4,000,000 evaluation budget). R&E staff are also available to  State Commissions for their evaluation questions and make resources  (e.g., research briefs summarizing effective interventions, online  evaluation planning and reporting curricula) available to them and the  general public. AmeriCorps awards investment fund grants to State  Commissions ($8.5 million in FY20), of which approximately one-third will  be used for data and evidence capacity building activities based on prior  year activities.   ■ Department of Labor. Grantees and programs that participate in DOL  evaluations receive technical assistance related to evaluation activities  and implementation such as the Evaluation and Research Hub (EvalHub).  DOL agencies, like ETA, are also making a concerted effort to help states  and local areas build evaluation capacity to meet the program evaluation  requirements for the Workforce Innovation and Opportunity Act and  Reemployment Services and Eligibility Assessment (RESEA) through  tools such as RESEA program evaluation technical assistance (RESEA  EvalTA). A suite of evaluation technical assistance resources is being  developed throughout FY20, including webinars and other tools and  templates to help states understand, build, and use evidence. DOL’s  evaluation technical assistance webinar series for states has been posted  online to the RESEA community of practice.   2. State Examples:  ○ The Texas Workforce Commission has developed an evidence framework that  clearly defines the process by which workforce practitioners can begin to develop  and use evidence of effectiveness in grant-funded programs, and the state can  evaluate programs and begin to develop evidence of effectiveness. Texas is  implementing a two-pronged approach that will link grant funds directly to priority  outcomes while continuing to support innovative practices. This approach will  create incentives for grant applicants to identify and use program models that  have demonstrated a record of effective outcomes. To continue to encourage  innovative, but less-tested program models, the state designed an evidence tier  framework to support a graduated method for programs and applicants to adapt  to evidence-based grants. Performance-based outcomes metrics and prior grant  outcomes data will be required in the application process, where relevant. An      11  evaluation process is also being developed. Embedding outcome-based  applications and outcomes reporting in state workforce grant programs will help  the state learn about the implementation, effectiveness, and cost of various  approaches.   ○ In Washington, a 2013 Executive Order established Results Washington to  strengthen performance management and continuous improvement throughout  Washington state government. From 2014 to early 2020, Results Washington  conducted Results Review meetings with the Governor 10 times per year. The  meetings, recorded and publicly posted, allowed the Governor and state agency  directors to discuss objectives, improvement strategies, and metrics. Results  Washington is currently refocusing its efforts toward a new Public Performance  Review process. This new process creates the opportunity to better partner with  state agencies on complex, cross-enterprise projects. The state is to develop an  approach that fosters partnership and focuses on the outcomes that matter to  state agencies, the Governor, and ultimately the state of Washington.   ○ Tennessee’s Governmental Accountability Act of 2013 established a statewide  performance management system, Transparent Tennessee. The Office of  Customer Focused Government and the state’s Chief Operating Officer  continuously track and monitor performance data and report publicly available  operational performance on Transparent Tennessee’s dashboards, which include  specific goals, targets, and performance data for each of the state’s strategic  priorities. The site also includes state fiscal data as well as OpenMaps, which  showcases key metrics and an interactive budget tool.   ○ In Colorado, the Colorado State Measurement for Accountable, Responsive and  Transparent Government (SMART) Act requires all state agencies to submit  annual performance reports to the state legislature as part of the state’s budget  process. In addition, the state’s FY 2020-2021 budget development instructions  (pp. 10-12) prioritize new program requests “based on the evidence and body of  research supporting the program’s effect on desired outcomes and proposed  implementation plan.” In the FY 2020-2021 budget cycle, the state applied an  evidence continuum to budget requests and used that criteria to inform resource  allocation decisions.   In addition, the Colorado Governor’s Office and the Colorado Evaluation and  Action Lab co-designed the Linked Information Network of Colorado (LINC) to  facilitate data sharing for research and analytics. The Network is designed to      12  share data across state agencies and provide de-identified data to perform  robust, academically rigorous research to inform policy. LINC has a three-tier  legal structure, which includes: (1) an enterprise memorandum of understanding  (eMOU) signed by all data providers; (2) data-sharing agreements to secure,  handle, and anonymize data for all LINC projects; and (3) data licenses with roles  and responsibilities for users of LINC project data. In addition, the Colorado  Department of Higher Education was the first state agency in the nation to  partner on a pilot project with the U.S. Census Bureau to match federal  unemployment insurance data with postsecondary degree completion data. At  the state and county level, the Colorado Department of Human Services’ C-Stat  performance management system facilitates data sharing among its 64 counties  by providing dashboards to track key metrics and Performance and Partnerships  Exchanges to facilitate sharing of best practices.  ○ In Connecticut, a 2018 law required each state agency to designate an agency  data officer to manage high-value data sets and coordinate data-related activities  with the state Chief Data Officer. The Chief Data Officer, along with individual  agency data officers, is required to biannually update the state data plan, which  covers open data and creates data standards for agencies. The plan also  contains 11 principles and accompanying practices that all agencies should  adopt to improve their management, use, sharing, and analysis of data. In  addition, a 2019 law required a report on the legal issues surrounding  interagency data sharing. Based on analysis of 17 state agencies and 224 data  sharing agreements, the report recommends: 1) establishing a coordinated  governance structure for cross-agency data sharing, and 2) implementing cross- agency data-sharing agreements that are more flexible and durable. Building on  this report, Connecticut released a Data-Sharing Playbook in 2020 to help  agencies share data safely, securely, and ethically.   ○ In Ohio, a 2019 executive order consolidated state data systems into the  InnovateOhio Platform, which uses data as “a shared strategic asset” whose  “value is multiplied when data sets are linked across programs and  organizations” through data integration and management tools. The executive  order created a presumption of data-sharing between state agencies, except  where a specific legal prohibition is identified in writing. Since its launch,  InnovateOhio and the Ohio Department of Administrative Services have  collaborated with state agencies to incorporate 1,600 information systems into  the State’s cloud environment. As of June 2020, the InnovateOhio Platform  recovered over $1 million in duplicate payments by applying a data analytics tool      13  to state agency spending ledgers.   ○ California released its state data strategy in 2020 and its statewide Open Data  Policy encourages departments to share data in standard and accessible formats  through the California Open Data Portal. As outlined in the California Open Data  Handbook, the state’s open data efforts are designed to improve collaboration,  expand transparency, encourage innovation, and increase effectiveness. In  addition, the state hosts CalData, a professional network for government officials  and partners to promote the best uses of open data.    ○ A Virginia 2020 executive order established data governance bodies to improve  data sharing between state agencies and localities. The Executive Order  implements the recommendations from the 2019 publication Data Sharing and  Analytics Governance Structure for the Commonwealth of Virginia Report. The  Virginia open data portal also features resources on data use, a data dictionary,  and an open data catalog.   ○ Indiana’s Indiana Data Partnership, launched in 2019, brings together  government, nonprofit, and private sector entities to share data, talent, and  technology to solve key challenges impacting Indiana residents. The Partnership  was formed as an extension of the Indiana Management Performance Hub to  create a secure, replicable, and sustainable framework  to help partner  organizations use shared data in coordinating efforts and  maximizing holistic  solutions. Initial projects included combating the opioid epidemic, improving  education and workforce development, mapping local health delivery, and a  networking analysis.  4. The Commission on Evidence-Based Policymaking (See: www.cep.gov) recommended  the creation of a National Secure Data Service (See Commission Report at www.cep.gov).  Do you agree with this recommendation, and if so, what should be the essential features  of a National Secure Data Service?  RFA agrees with the Commission’s recommendation to create a National Secure Data Service.  We believe the best way to carry out this recommendation is, as recommended by the Data  Foundation in its July 2020 strategy, to create a new federally funded research and  development center (FFRDC) at the National Science Foundation (NSF). The essential features  of this approach are detailed in the Data Foundation’s strategy, but in summary they include:        14  ● Responsibility and organization within NSF’s National Center for Science and  Engineering Statistics (NCSES), which is a CIPSEA-covered principal federal  statistical agency.  Being housed within NSF would make the FFRDC subject to federal  oversight, and accountable to Congress and OMB. In addition, existing within NCSES  would permit the FFRDC to operate within the CIPSEA framework re-authorized by  Congress in 2018, including both data sharing and use capabilities. While this attribute  differs from the Evidence Commission’s Recommendation 4-1, in part, it allows for the  same intent for the capacity to engage in record linkage and access.   ● Transparency. The FFRDC should be required to make periodic reports to OMB and  Congress about its activities and projects. It should also be required to communicate  with the public about its projects and the value of its undertakings.   ● Accountability. The FFRDC should be periodically reviewed by Congress, GAO, and  the NSF Inspector General to ensure adequate compliance with stated processes and  CIPSEA authorities through performance and compliance audits. A user feedback  mechanism should also be created.    ● Interagency Cooperation. For the FFRDC to be successful federal agencies will need  to be encouraged to share their data and improve access to that data. This  encouragement should come from OMB and the Interagency Statistical and Evaluation  Councils as well as the Chief Data Officers Council. In addition, NSF will need to  establish a viable, streamlined business process for project approvals, particularly when  projects require data from multiple agencies.   ● Open, competitive contract award process. The contract award for the FFRDC  should be open and competitive. Any bidder should have to demonstrate its capabilities,  including its ability to jointly: (1) operate the core capabilities for data sharing, linkage,  and compliance with CIPSEA protections, (2) develop and deploy current and future  privacy-protective technologies in coordination with federal agencies, (3) coordinate with  federal agencies (sponsor and non-sponsors) as well as the research community and  other qualified individuals for approved projects, (4) operate within the guidance of an  oversight committee, (5) have a demonstrated ability to recruit and retain qualified staff  with appropriate and relevant expertise; (6) operate business processes for project  approvals, (7) maintain accessible project inventories, and (8) implement an ongoing  program of continuous improvement in meeting customer needs.   ● Governance board. Consistent with the Evidence Commission’s Recommendation 4-2,  NSF should establish a governance board to provide general guidance on policies and      15  practices implemented by the FFRDC.   ● CIPSEA designation. Either Congress should designate the FFRDC as a CIPSEA  agency in law, or the Director of NCSES as part of the FFRDC contract should designate  the FFRDC as a CIPSEA agent.   ● Data leadership. The Executive Director of the data service should have experience in  government data activities and deploying privacy protections.   ● Training. The FFRDC should be required to conduct a variety of activities that explicitly  support training and education for potential users of the data service including low- or  no-cost educational opportunities for internal government and external researchers,  industry stakeholders, non-profits, and government agency staff, and should explicitly  communicate the limitations and restrictions imposed by the CIPSEA privacy framework.   ● Government-wide learning agenda for researchers. The FFRDC should compile an  analysis of questions within individual agency learning agendas that can be addressed  with available microdata within the existing infrastructure, support researchers in  understanding those questions and accessing the data, and include any stakeholder  feedback that was provided in response to the questions.  DATA SERVICES TO FEDERAL, STATE, LOCAL AGENCIES AND THE PUBLIC  8. What are the most pressing data needs of state and local decision makers and how  would making data accessible from federal agencies help meet those needs? To share  data, what guarantees do data owners (or data controllers) need regarding privacy, data  stewardship, and retention?  For states, a pressing need is to expedite data sharing across and within their agencies. Some  have solved this with state data by creating formal, standardized, and easy to apply agreements  that agencies can use to share data without risking privacy or security. Some, like Nevada, have  dedicated data privacy experts to support effective and legal data sharing and access. Federal  agencies can support this need by both enabling linked data (as discussed in response to  question 4 above) and by issuing coordinated federal guidance that eases restrictions on data  sharing, investing in data infrastructure, coordinating data investments, and providing more  clarity about the allowable uses for program funds to support data sharing, collection, and other  activities. For example, the HUD’s Community Development Block Grant includes a 20% set  aside for administrative costs, which may encompass evaluation-capacity building efforts and  evaluations of CDBG funded interventions. Further clarity on such authorized uses to states,      16  localities, and other grantees could increase evidence-building capacities that states and  localities need and seek.   Another one of states’ most pressing needs is to be able to understand the long-term impacts of  their services. Millions of young people are being served either through traditional education or  other social service programs and once they “age out,” it is incredibly hard to see what happens  to them over the long-term so states are not able to measure the impact of their programs. The  same issues exist for adults they serve, especially if they provide training or refer them to other  organizations that can help them. There is no holistic view of how and when a person interacts  with one or more programs in order to measure impact. Not having the full picture of that person  and being limited to just the data available from a siloed agency means that states cannot  evaluate as many factors, and they cannot account for complementary services from other  programs before, after, or even parallel to their own services.   For example, consider two identical youths supported through the WIOA Youth program, One  goes to college, the other doesn’t and doesn’t go to other post-secondary education training. If  the state just looks at wages X years later, they are going to likely see one did very well and the  other didn’t. Without the information about post-secondary enrollment/achievement, they can’t  put longitudinal outcomes in context and appropriately weigh them in their analysis of the effect  of their WIOA Youth program.   Another pressing need is enhanced wage records. Labor Market and Career Information  (LMCI), through a cooperative agreement with BLS, manages key statistical programs to  produce employment, wage, and other labor force data. Bureau of Labor Statistics (BLS)  programs rely heavily on Unemployment Insurance (UI) wages records for the foundational  data, further enhanced through the collection of survey-based data. These programs would  benefit from the addition of variables to the quarterly wage record reports that employers submit  as part of the UI program, submitting an enhanced wage record. Consistent definitions for wage  record elements are needed in order to properly provide data comparison across all states.  Additional data elements such as, date of hire, occupation title and hourly wage rate would  improve the accuracy and overall quality of the data and enhance the states’ ability to measure  education and training outcomes. BLS maintains strict confidentiality rules and guidelines to  protect each respondents’ confidentiality and data collected are used for statistical purposes  only.  On the city level, particularly in the past few months, the most pressing need being discussed is  a federal standard for public health data (specifically COVID data). At least one city is taking it  upon themselves to form an intra-governmental data-driven COVID task force but is struggling  because the state, county, and city lack consistency around their data policies and processes.       17  Additional pressing needs revolve around the sharing of best practices. For example, cities in  Results for America’s economic mobility cohort often express a desire for information about  what other cities are doing to equitably distribute the increased Community Development Block  Grant funds they received through the CARES Act. Similarly, cities really want to know what the  most effective approaches or interventions are for getting people who have been forced out of  work by COVID back into jobs. Loss of income and work have been hitting their most vulnerable  residents the hardest and they want to make sure the steps they are taking can help them  recover quickly and equitably. But, this requires access to data and information they do not  currently have.   Also, cities such as Racine are working with their local workforce development boards to track  wage data specific to graduates of city GED programs. Being able to extract those individuals’  wage data in an ongoing and systematic way is critical to long term efforts to scale and sustain  such programs and to help the City assess the effectiveness of other local workforce  interventions.  9. What are the key problems and use cases where collaborative work between federal,  state, and local authorities' data analysis can inform decisions? What are key decision  support tools? How would greater communication about data and tools benefit expanded  evidence building?  Overall, one of the main issues states encounter is inconsistency in definitions of common data  elements and coding structures among federal, state, and local agencies. One specific example  is how workforce agencies define industries. Cyber Security & Infrastructure Security Agency  (CISA) released 16 critical infrastructure sectors. These did not align to NAICS sectors and  states ultimately decided how occupations aligned to CISA sectors based on criticality and local  needs, taking different approaches in what was considered “essential.” Consistency among  definitions would allow all agencies to gather and report data in a more meaningful way, making  sure we can provide measured relevant outcomes. Federal evaluation clearinghouses such as  CLEAR and Crime Solutions are tools that help to showcase effective models. CLEAR’s stated  goal is to “make research on labor topics more accessible to practitioners, policymakers,  researchers, and the public more broadly so that it can inform their decisions about labor  policies and programs.” As more evidence-based grantmaking occurs in states, they will look to  add effective models and program evaluations to these national tools in coming years.   In terms of a use case where collaboration was effective and critical, state responses to COVID- 19 rises to the top. State’s COVID-19 responses were exemplary, with some states tracking  state allocations of federal emergency funds and response efforts through robust data  dashboards. For example:      18  ○ Minnesota built a comprehensive public data dashboard that tracks health and  economic data, including response data on hospital capacity, critical care  supplies, child care, and funding. The dashboard also tracks the disparate  impacts of the virus on communities of color to enhance collaboration with  stakeholders and “eliminate systemic barriers so communities of color and  indigenous communities can recover with dignity and resiliency.” Such a  collaboration includes an ongoing partnership with J-PAL North America that is  leveraging the data to identify how to increase take up of COVID-19 testing in  Black and Latinx communities based on local needs and preferences.   ○ In 2020, California launched the California COVID Assessment Tool to identify  potential COVID-19 hotspots, predict which hospitals might reach capacity, and  proactively allocate resources to such hotspots. This innovative assessment tool  is a “model of models,” which incorporates the statistical projections of several  leading research institutions. Notably, the assessment tool allows residents to  create their own scenarios for transmission potential in the coming months  depending on specific public health guidelines. Further, California released the  source data sets on California’s Open Data Portal, allowing the public to examine  the data underlying the Assessment Tool.   ○ The Connecticut Departments of Education and Social Services leveraged data- sharing agreements by matching student and SNAP benefit data to automatically  certify SNAP Pandemic EBT for more than 287,000 Connecticut students who  receive free or reduced-price meals. This allowed the state to provide meals to  82,000 students participating in only the National School Lunch Program and  School Breakfast Program, but who do not receive food assistance through  SNAP, Medicaid, or other food assistance programs. The state also partnered  with food retailers to allow SNAP enrollees to use their benefits to purchase  eligible food items online.   ○ North Carolina and Tennessee (among other states) had pandemic relief tracking  dashboards.   INFRASTRUCTURE FOR MEETING PUBLIC AND EVIDENCE BUILDING NEEDS  10. What basic public data services are essential for a data service to address existing  capacity gaps and needs? What infrastructure or incentives can the federal government  create that locals and states cannot?      19  The federal government can better facilitate and support data-linkage and integration. The most  efficient data sharing model would be one that is centralized and standardized. Anything else  requires bilateral agreements between agencies and states and local governments. It drives up  the cost and changes the cost-benefit analysis on doing evidence-based policy work. It  encourages people to try to maximize their siloed data – because it is too hard to get more.  Federal laws, programs, and funding should require secure data sharing and evaluation work as  a precondition to access the money. This should apply to federal agencies as well as to state  and local government agencies.   For example, states have implemented education longitudinal data systems through the U.S.  Department of Education’s SLDS grant, which was administered most recently in FY20.  Connecticut’s statewide longitudinal data system, P20 WIN, brings together workforce,  education and supportive services data to inform educational policy and practice. Created by  participating agencies, it houses extensive documentation, including data-sharing agreements,  a robust data management process, and a data dictionary. In 2020, P20 WIN received an  expansion grant through the National Center for Education Statistics to build agency analytical  capacity and to expand P20 WIN to include information from state human service agencies.      