 1        Yale University PO 208264    New Haven CT 06520-8264  Campus Address: 37 Hillhouse Avenue New Haven CT 06511    February 9, 2021   Memorandum to the Advisory Committee on Data for Evidence-Building  From:  David Wilkinson, Executive Director, Tobin Center for Economic Policy, Yale University  Former Chief Performance Officer and former Commissioner of Early Childhood, State of Connecticut Former Director, White House Office of Social Innovation    Kathy Stack, Consulting Advisor to the Tobin Center for Economic Policy, Yale University    Former Vice President, Arnold Foundation Former Deputy Associate Director for Education, Income Maintenance and Labor, U.S. Office of Management and Budget   Subject:  Comments1 for the Advisory Committee on Data for Evidence Building (Document  # 2020-27489) on Questions 1, 2, 3, 7, 9 and 10  Thank you for the opportunity to submit comments to inform your committee’s analysis and recommendations.  Our comments reflect our shared insights from working in senior federal policy positions at the White House Domestic Policy Council and the Office of Management and Budget as well as our experiences working in or with state and local governments on projects that require integration of data across systems.  Some of our ideas were key motivators for a project we recently launched at the Tobin Center – “The Hotlist Project:  Actionable, Data-Intensive Research Priorities” – which is described in more detail below.    Our comments address questions 1, 2, 3, 7, 9, and 10 in the Federal Register notice.         1 General disclaimer: Nothing in these comments are intended to represent – nor should be construed as – an official or unofficial position of Yale University. Rather this memorandum presents the suggestions and opinions of authors affiliated with the Tobin Center for Economic Policy at Yale, based on their relevant policy experience, in response to the formal public solicitation of comments in the Federal Register.    2   Question 1:  What are the main challenges faced by national, state/provincial, or local governments that are trying to build a basis for evidence-based policy?  Briefly, describe the bottlenecks and pain-points they face in the evidence-based decision-making process.   • At the state and local level -- where improving outcomes for individuals and families requires effective coordination of multiple programs serving the same populations – many of the barriers to using data to improve decisions are the result of unclear and confusing federal requirements.  It is no one’s responsibility in the federal government to step into the shoes of state and local leaders who are trying to use data to improve decision-making but are fearful of running afoul of federal requirements.  States and localities need greater clarity and strong encouragement to:   o Use program funds for data and evidence-building activities; o Braid and blend funds from multiple sources to build cost-effective infrastructure,  analytics and evaluation capacity (including staff recruitment and funding) that supports multiple programs;  o Share data across multiple programs that serve the same populations, including for activities that are covered by multiple federal privacy laws such as FERPA and HIPAA.  These challenges could be addressed through an aggressive, cross-agency technical assistance strategy to develop coordinated guidance, concisely written in plain English, which is broadly disseminated to program administrators, financial managers, attorneys, and auditors who work at the federal, state, and local levels.     • At the federal government level, while progress is being made on learning agendas and improved data infrastructure, there are serious gaps that will impede its ability to use data and evidence to address the nation’s most pressing challenges.  Gaps include:   • Lack of mature processes for:  o Identifying and prioritizing policy challenges and key questions that can be more effectively understood and addressed by integrating data from different systems that sit in different federal, state, or local agencies or with their contractors and grantees. To date, federal agency learning agendas have been narrowly focused on specific agency priorities and programs without an eye toward national challenges that require cross-sector and intergovernmental collaboration, including President Biden’s priorities for effective pandemic response, economic recovery, and racial equity.  o Designing efficient, re-usable data-linkage and analysis processes for building evidence, so that individual projects that link data are not “one-off” studies or dead-end pilots that fail to build capacity for future applications that could be taken to scale.  o Collaborating with non-federal stakeholders to identify shared priorities and key barriers and to co-create efficient solutions that will maximize the benefits to federal, state and local governments, providers, and the public.  For example, the same data-linkage infrastructure solutions created to support research and evaluation could be used to efficiently generate program performance    3   information (e.g., employment outcomes), dramatically streamlining the costly and burdensome data gathering and reporting processes that states, localities, and other grantees now use.    • Human capital gaps that result from underinvestment in recruitment and training of data and research experts.  Also, relatively few federal agencies have developed mature programs that utilize academic-government collaborations to strengthen their research and evaluation capacity at low cost.     Question 2:  What are examples of high-impact data uses for evidence-based policy making that successfully effected change, reduced costs, or improved the welfare of citizens?     Integrated data can be used to:  • Respond to crises such as the pandemic.   For example, Allegheny County PA uses integrated data to publicly report COVID hospitalization and case rates by race and reports outcomes by demographic group, which inform strategies to improve outreach and targeting of services.  Few other jurisdictions have this capacity, in part because the federal government has not created the financial incentives to encourage broader adoption of these approaches.  See:  https://www.alleghenycountyanalytics.us/index.php/2020/06/15/allegheny-county-covid-19-data-detailed-dashboard/  • Generate cost-saving estimates to inform policy:  At the state and local level, several communities have linked emergency room and jail data to reveal the portion of homeless population for which supportive housing would yield savings.  This analysis motivated numerous communities to launch Pay for Success projects focused on supportive housing, listed here: https://pfs.urban.org/get-started/content/pay-success-and-housing.  At the federal level, during the GW Bush administration, matches between the Education Department’s student aid records and IRS tax data measured the amount of Pell grant funding that had been awarded to ineligible students who exceeded income thresholds.  The findings informed the Obama administration’s decision to allow student aid applicants to pre-populate their FAFSA student aid applications with IRS tax data instead of self-reported data.  This policy reduced Pell overpayments, and Congress was able to redirect the savings to increase the size of Pell grants to eligible students.    • Generate rigorous evidence through grants to state and local governments and non-profits:  Government can require grantees to embed rigorous evaluations into their program designs that utilize high quality administrative data to measure results at low cost.  The Education Department’s Education Innovation and Research (EIR) program, which uses a tiered evidence design, requires rigorous evaluations that often leverage State Longitudinal Data Systems to efficiently and accurately measure student learning outcomes.    Treasury’s Social Impact Partnerships to Pay for Results Act is designed to build evidence about effective interventions that improve impact on beneficiary outcomes and generate cost savings to government:  https://home.treasury.gov/services/social-impact-partnerships/sippra-pay-for-results.  (Note: The capacity to learn from SIPPRA    4   grants would be significantly increased if evaluators could access outcome and financial data held by federal agencies.)  • Streamline and coordinate services and reduce redundancy: States are integrating data across health and human services systems to improve enrollment and eligibility verification and strengthen program coordination.  Some are building upon this infrastructure to improve their analytics capacity.  See:  https://www.cbpp.org/research/state-innovations-in-horizontal-integration-leveraging-technology-for-health-and-human     • Perform predictive analytics to support smart targeting of funds: Some states and localities are using predictive analytics to Identify common patterns of system engagement that precede costly safety net usage, thereby enabling programs to more efficiently target limited resources where they can maximize impact. In Oregon, researchers found seven factors in birth record data that point to a 40% likelihood of later child welfare system engagement, allowing more intelligent targeting of preventive services to families most likely to need support, which drives future savings.  See Oregon’s Safety at Screening Tool:  https://www.oregon.gov/dhs/ORRAI/Documents/Oregon%20DHS%20Safety%20at%20Screening%20Research%20Brief.pdf   • Develop and publish consumer report cards:  By linking data across systems, government can generate and disseminate key performance indicators that are useful to both consumers and government decision-makers.  The U.S. Department of Education’s College Scorecard links student aid program data with IRS tax data to generate average earnings for graduates of higher education institutions, by program of study.   See: https://collegescorecard.ed.gov/  • Improve performance metrics.  Researchers can study what early indicators of success are the best predictors of long-term impacts using methods similar to the surrogate index described in this Raj Chetty paper:  https://opportunityinsights.org/paper/the-surrogate-index/.  This type of analysis could help government programs develop improved performance metrics that incentivize broader adoption of strategies correlated with long-term impacts.        • Deploy data-driven behavioral insights to improve lives and increase efficiencies: Governments can use “nudge” approaches and A/B testing to spur key actions, such as timely community college re-enrollment that reduces drop outs, follow through on tax payment, and increased enrollment in financial savings programs.  This was a major focus of the Obama administration’s White House Social and Behavioral Sciences Team: https://sbst.gov/  • Track and improve performance of services in real time: By providing service providers with real-time data, providers can better support clients.  In Santa Clara County (California), social workers are pinged if a mental health client has a destabilizing event, such as an arrest, so the client can be intercepted and provided appropriate care at lower costs and with better results.  See: https://www.thirdsectorcap.org/santa-clara-county-partners-in-wellness/     5   Question 3: Which frameworks, policies, practices, or methods show promise in overcoming challenges experienced by governments in their evidence building?  Government’s capacity to overcome challenges to evidence-building can be dramatically accelerated by:  • Selecting important policy challenges and important associated research questions that require government-researcher collaborations; and  • Enlisting collaboration partners to co-create efficient processes and infrastructure (including data-linkage infrastructure) for answering the questions; and  • Designing new processes and infrastructure so that can be re-used to address a wide range of policy-relevant questions.     Many of the nation’s most pressing challenges related to improving health and economic well-being require collaboration between multiple federal agencies, state and local governments, and their service delivery partners who work on the front lines.  Academic researchers and data scientists as well as philanthropies can contribute expertise and resources.  To demonstrate how the federal government could embed the above approach into its evidence-building strategies, the Yale Tobin Center for Economic Policy has recently launched “The Hotlist Project:  Actionable, Data-Intensive Research Priorities”, which we hope will inform the Advisory Committee’s recommendations.   Over the past three months, we have developed several initial high-impact project concepts based on consultations with federal agency staff at Treasury, DOL, ACF, HUD, ED, and VA;  state and local government officials in Virginia, Rhode Island and California; academic researchers and data scientists at MIT’s JPAL North America,the Policy Lab at Brown University, and faculty at Yale and Georgetown Universities; numerous philanthropies; and others.  All of these initial project ideas would leverage linked administrative data and could utilize academic-government collaborations to make faster progress and better results.   We have already won philanthropic support to launch the project and are beginning discussions with over a dozen philanthropies to gauge their interest in supporting the development of some of the specific project concepts with government and academic partners.  Potential roles for philanthropy include supporting academics who could serve inside government as IPAs or financing workshops to scope out and co-design projects with federal, state, and local officials, academic researchers, and other relevant parties.    A few illustrative project concepts that have emerged from our discovery process with federal agencies, academia and philanthropy include: 1. Transforming processes for measuring employment outcomes in federally funded programs  supporting economic mobility, including employment and training, prisoner re-entry, Americorps, substance use treatment, and subsidized housing.  This collaboration would use academic data scientists and researchers who serve as IPAs in Treasury, HHS, and other key agencies to develop infrastructure and processes for linking program participant data with tax data held by IRS and potentially quarterly wage and employment data held by HHS’ National Directory of New Hires.  The methodology would be modeled on the College Scorecard, which    6   links Education Department student aid data with IRS tax data to produce aggregated earnings by school and program of study.  The new infrastructure and processes could be used to:  • Produce “employment scorecards” for education and training programs, providers, interventions, and jurisdictions to promote accountability and provide useful information to a broad range of decision-makers.    • Improve capacity to conduct low-cost, high quality RCTs and follow-up studies of the long-term impact of interventions on employment outcomes  • Create efficient infrastructure available to state and local jurisdictions and training providers seeking to shift from activity-based accountability to outcome-focused accountability.    • Significantly reduce burden and increase the accuracy of grant program performance reporting that often requires grantees to either collect self-reported income and earnings from prior program participants or to use incomplete data from state employment  systems.    Building capacity to generate employment scorecards would enable grantees to take advantage of flexibility recently included in section 200.102 of OMB’s government-wide grant regulations, which allow standard grant reporting requirements to be waived “in support of innovative program designs that apply a risk-based, data-driven framework to alleviate select compliance requirements and hold recipients accountable for good performance”.    2. Establish a “SIPPRA Data and Evaluation Lab” .  The Social Impact Partnerships to Pay for  Results Act of 2018 established a $100 million Treasury Department Fund to make outcome payments for state and local projects, backed by strong evidence, that hold potential to improve outcomes for vulnerable populations while reducing government costs.  A portion of the government savings much be federal.    Currently, Treasury requires each project applicant to design the evaluation, identify data sources, and negotiate data-sharing agreements, which are burdensome, time-intensive, and costly steps that have been a major hurdle for previous Pay for Success projects.  Because the federal government holds some of the most accurate and complete data for measuring program outcomes, costs, and savings for certain SIPPRA-eligible interventions, facilitating access to federal data and utilizing standard measurement and evaluation methodologies could significantly enhance the quality of SIPPRA evaluations while lowering their costs.  A cross-agency team, supported by academic IPAs, could create a SIPPRA Data and Evaluation Lab to:  (1) create internal capacity to conduct key portions of SIPPRA evaluations using the scorecard approach above; (2) create standard protocols and data use agreements for accessing federal data that can be shared with external evaluators; and (3) develop standard methodologies and templates for measuring impacts, costs, and savings to improve comparability across projects.  When appropriate, evaluators for approved SIPPRA projects could conduct evaluation activities inside the federal government while serving as IPAs.    The Lab could also be used for non-SIPPRA evaluations that measure impact on outcomes and/or cost savings using federal data, which could guide future policy decisions and legislation.  Historically, Congress and the Executive Branch have been able to agree on bipartisan legislation to mandate cost-savings measures in entitlement programs if a data-   7   match provides a reliable savings estimate that the Congressional Budget Office can score as an offset to a new spending initiative.     3. Study ways to improve targeting of federal resources based on objective indicators of need and racial equity.  By building capacity to utilize Treasury’s USA Spending data base to compare actual funding allocations to states and localities to alternative allocations based on objective indicators of need, researchers could assist federal, state, and local policymakers to adjust the criteria they use to allocate funds.  To better understand racial disparities in how funds are allocated, Treasury’s USA Spending data could be linked to racial and ethnic data held by another agency, such as the Social Security Administration.  The findings could be used to inform allocation adjustments that are based on objective indicators of need that correlate with racial disparities.     4. Conduct feasibility studies using federal-state data linkages.   A number of states have created  integrated data platforms for merging individual-level data across state-administered programs.  While these platforms can answer many of a state’s priority policy questions, gaps in the data limit accuracy and completeness.  (For example, employment data held by a state may not include residents who work outside the state, or may include employment data for people who work in the state but reside in a different state.)  A cross-agency, intergovernmental project team involving federal agencies that hold high-value national data (e.g., IRS, HHS, SSA, ED, Census, HUD, VA) could collaborate with several states to identify important questions that require linking data across levels of government.  The collaboration could develop and test efficient ways to answer key questions of interest to multiple states. This project could help inform the design of a federally funded secure data service that could be used for a broad range of questions (e.g., the Coleridge Initiative’s Administrative Data Research Facility).  The project could leverage existing partnerships between state governments and academic institutions (e.g., the Policy Lab at Brown, California Policy Lab, Colorado Evaluation and Action Lab) and use IPAs in federal agencies to strengthen federal agency capacity for this project.  The groundwork for future projects that link state health and human services data with federal tax data has already been laid through a data-linkage project already underway between the Virginia Department of Social Services and the IRS.    Question 7: Government agencies have argued that secure data access has value because it (1) improves service delivery; (2) improves efficiency (lowers cost); (3) produces metrics for performance measurement; and (4) produces new learnings/insights from the data.  Which of these propositions do you agree with and why?  Do you have examples that demonstrate these benefits?  Do you have other examples of the value of secure data access?  We agree with all four propositions, which are illustrated by the examples in our response to question 2, above.  It’s notable that the secure data linkage process that was established many years ago between the Education Department and IRS to measure Pell grant overpayments (in order to improve efficiency and lower costs) laid the groundwork for other uses of linked data, including:    8   • Improving service delivery and lowering administrative costs by allowing student aid applicants to authorize IRS data to be shared with Education to prepopulate the FAFSA application;   • Producing new metrics for performance measurement for student aid programs by measuring average income of former college students, by school and program of study; and  • Producing new learnings/insights from the merged data by making it available to outside researchers, such as Raj Chetty and his colleagues at Opportunity Insights who have used the merged data for groundbreaking research on economic mobility.    These examples illustrate how new data-linkage processes and infrastructure developed for one purpose can be re-used to improve the effectiveness and efficiency of other critical government functions, including but not limited to research and evaluation.    Question 9:  What are the key problems and use cases where collaborative work between federal, state, and local authorities’ data analysis can inform decisions?  What are key decision support tools?  How would greater communication about data and tools benefit expanded evidence building?  Kathy Stack’s recent paper, “Harnessing Data Analytics to Improve the Lives of Individuals and Families: A National Strategy” describes urgent national challenges related to the pandemic, economic recovery, and equity that call for strong collaboration between federal, state, and local governments. (https://www.dayoneproject.org/post/harnessing-data-analytics-to-improve-the-lives-of-individuals-and-families-a-national-data-strategy).  The paper includes key questions that states and localities should be able to answer to improve the impact of federal programs, such as:  • Need:  What are the needs of the various population groups who are eligible for services, and how are they different or the same?    • Resource and service allocation: Who is receiving services and benefits, and who is eligible but not receiving them?   Are services and benefits reaching those who need them most?    • Mix of services and benefits: Is the mix of services and benefits appropriate and effective for the different populations served?  Are services effectively coordinated across programs?  • Equity:  Do our analytical methods and algorithms reinforce bias in policy, resource allocation, and other decision-making?  What safeguards would prevent this?  • Outcomes:  What outcomes are we achieving? How do they compare with expected levels of performance?  • Comparing alternative approaches: What alternative approaches have the greatest positive impact?  Which are most cost-effective?    • Operational efficiency:  Are operations being conducted in the most efficient way?  What changes improve the customer experience while reducing costs?  • Return on investment from upstream prevention: What preventive measures avoid negative outcomes and downstream costs (e.g., actions to reduce homelessness or address social determinants of health)?  Which would have the highest return on investment?  • Error, fraud and abuse:  What individuals or entities are receiving funds they are not entitled to, based on data available through a different program?   COVID-Specific Examples:    9   • High-risk groups:  For specific communities, what are the key characteristics of people most susceptible to COVID-19, including race/ethnicity, age, underlying health conditions, reliance on public transportation, housing status, and types of employment?  • Effective interventions:  What approaches and interventions (e.g., contact tracing, registration upon entering a business, temporary housing for members of a COVID-affected household) have a measurable effect on the rate of COVID-spread, or factors that contribute to spread?    • Economic impacts:  Are individuals and businesses that were eligible for emergency assistance, and in greatest need, receiving assistance?    • Program integrity:  What individuals and entities are receiving assistance from multiple emergency programs, at least one of which they are not eligible for?     The paper lays out a five-part strategy for the federal government, working in partnership with state and local governments and outside experts, to create the enabling conditions for rapid modernization of data capacity to answer these and other questions.   The key elements are:  • Establish a White House Data and Analytics Working Group, led by senior White House and OMB officials and supported by a task force, which includes state and local officials.  • Set new expectations for data use by state and local governments and provide funding and incentives through regulatory and administrative reforms.  This could include allowing federal Medicaid funding to be used to build cross-program data and analytics capacity to improve outcomes for low-income populations.  • Provide technical assistance on key data-related issues, such as how to share data while protecting privacy, how to reduce reliance on costly vendor solutions that reinforce silos, and how to finance integrated data capacity by braiding and blending existing funding streams.  (While there is currently legal authority for state and local governments to finance data infrastructure and analytics capacity with braided funding, the federal government has failed to provide clear guidance.  Absent authoritative guidance, states and localities are reluctant to spend money on activities that auditors may question.)  • Build expertise using personnel exchanges, including by creating a network of academics serving as IPAs in federal agencies who can collaborate on cross-agency, intergovernmental evidence-building projects.  • Develop legislative proposals based on an analysis of federal, state, and local barriers and capacity gaps that cannot be solved through administrative action.   Other examples of how federal data can help inform state and local policy decisions emerged from a Chapin Hall-Census data linkage project launched in 2016 with support from the Arnold Foundation.  A Chapin Hall solicitation received 45 proposals from states and local governments seeking to link their data to federal data using the Census data-linkage infrastructure.  See https://www.chapinhall.org/wp-content/uploads/Admin-Data-for-the-Public-Good.pdf  The Chapin Hall report describes in detail the six proposals that were selected as pilots and the implementation challenges that the projects encountered in setting up data-linkage processes.  These insights may be highly relevant to the Advisory Committee’s work.       10   Question 10:  What basic public data services are essential for a data service to address existing capacity gaps and needs?  What infrastructure or incentives can the federal government create that locals and states cannot?  The federal government holds rich, complete data sets that states and localities could better utilize to inform their policy decisions.  One of the best examples is employment data held by IRS (annual income) and ACF’s National Directory of New Hires (quarterly earnings.)  These data can fill critical information gaps for states about people living in their state who work in another state, and people or living outside their state who work in their state.    Among the examples of incentives the federal government can create that states and localities cannot are:   • Federal grant programs can require state and local grantees to devise plans for how they will use data, analytics and evaluation to strengthen results and to report on significant findings.  (This information could take the place of unnecessary and burdensome compliance reporting that is not helping grantees improve performance.)    • For financing, the federal government can (1) clarify ways that existing funding streams can be used for data and analytics capacity; and (2) provide additional funding using Medicaid and OMB waiver authorities to finance integrated data systems and analytics capacity under current law.    • Further, new appropriations from Congress for state systems and/or data capacity can require states (1) to create interoperable systems that can link data to other state and federal systems serving overlapping populations, and (2) to make de-identified data available for research, evaluation and statistical activities.  If Congress provides new funding to states to modernize their UI systems, the Department of Labor should work with OMB and other federal agencies to strengthen and align incentives for states to integrate data from UI with data in other state-administered programs.  • Federal agencies can work with state and local agencies to streamline and standardize data collections so the data is more useful and burden is reduced.  Developing common data standards with state and local governments – as the Education Department did for State Longitudinal Data Systems and HHS did for electronic health records – can dramatically improve the utility and quality of data, promote interoperability, and ultimately reduce administrative costs.    • Federal agencies can allow state and local grantees to use the “Exceptions” provision (in section 200.102) of OMB government-wide grants guidance to develop alternative performance metrics that utilize linked data to generate useful and reliable outcome measures.  Grantees that can provide demographic characteristics of their program beneficiaries, and also authorize the use of linked data to measure outcomes and other key progress indicators, could be relieved from other reporting that is not required by statute.  The employment scorecard example, highlighted in question 3, could be an initial focus for this streamlined approach.        11   Other examples of federal incentives are described in the national strategy paper described above (https://www.dayoneproject.org/post/harnessing-data-analytics-to-improve-the-lives-of-individuals-and-families-a-national-data-strategy).  The federal government can also devise creative, legally permissible approaches to develop analytical tools that help states and localities utilize federally held data.  For example, the same methodology that IRS and the Education Department used to produce the College Scorecard could be adapted to measure employment outcomes in state and local grant programs and for federally funded training providers.  De-identified data about participants in state and local programs could be merged at IRS with tax data to produce reliable employment outcome information at a very modest cost. Similar capacity could be built at the Administration on Children and Families using NDNH data on quarterly earnings.        