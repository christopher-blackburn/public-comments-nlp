 Achieving Data Integrity  Comments for the Advisory Committee on Data for Evidence Building     Date:  February 9, 2021  Electronic submission     The Advisory Committee on Data for Evidence Building represents a series of important and commendable efforts in support of the Foundations for Evidence-Base Policymaking Act of 2018, which in turn advances our nation’s critical objective to promote the responsible usage, availability, and sharing of data assets for improved operations and decisions. As ardent supporters of both the legislation and the work that shaped it, we are honored for the opportunity to present our recommendations in response to the Department of Commerce Request for Comments.  Please find our responses to the Central Questions 1, 3, 4, 6, and 9 below, preserving the original numbering.       1.   What are the main challenges faced by national, state/provincial, or local governments that are trying to build a basis for evidence-based policy? Briefly describe the bottlenecks and pain-points they face in the evidence-based decision-making process.   The technological, organizational, and cultural systems needed as a foundation for evidence-based decision-making require Federal expenditures that represent a sizable investment of time, labor, and resources. Often, due to the substantial commitments and subsequent oversight, it takes considerable time for an organization to recognize that the tools and technology in service of ongoing operations are outdated. This creates multiple vulnerabilities, which leaves the entities open to significant risk across several domains:   1. Security: As software and tools age, exploitable weaknesses become increasingly evident, often leading organizations open to substantial but preventable security risks. Reliance on patches and updates are only sufficient if the legacy products are supported. Once they reach end-of-life, the vulnerabilities become more numerous and more difficult to correct, with the entirety of burden inherited by the organization.   2. Operational Readiness: Systemic approaches that are designed around specific technologies rely on the continued support and operation of those technologies, with greater problems incurred by the existence of dependencies in peripheral systems. The recent deprecation of tools such as Adobe Flash and Microsoft Silverlight may seem unimportant unless you are utilizing those tools for critical processes. If you have not replaced those systems, your processes will no longer function.   There is an additional disadvantage posed by confinement to a specific vendor or suite of products. Doing so creates vulnerabilities such as propensity for price gouging, outsourcing of intellectual and technical capabilities, and other limitations of high proprietary technologies. For example, “Federal Agencies’ Reliance on Outdated and Unsupported Information Technology: A Ticking Time Bomb,” a 2016 Committee on Oversight and Reform hearing, emphasized the critical nature of moving on from legacy systems and legacy languages. The hearing mentioned that over 1,500 staff members were retained for the purposes of upholding maintaining the legacy languages COBOL (1,085) and Fortran (613) (United States House Committee on Oversight and Government Reform, 2016.) This clearly indicates both economic and technological compromise.   From a talent onboarding and retainment standpoint, this also creates a barrier-to-entry as these languages have not been part of the curriculum in technical programs for years. In fact, even Turing award-winning computer scientist Edsger W. Dijstra wrote a letter to the Communications of the Association for Computing Machinery (ACM) in which he stated that, “The use of COBOL cripples the mind; its teaching should, therefore, be regarded as a criminal offence,” and that, “FORTRAN —"the infantile disorder"—, by    now nearly 20 years old, is hopelessly inadequate for whatever computer application you have in mind today: it is now too clumsy, too risky, and too expensive to use.” This was published in 1975. Dijstra is considered one of the most influential computer programmers, making critical contributions to the field and serving as the Schlumberger Centennial Chair in the Computer Science Department at the University of Texas at Austin.   3. User Acceptance: The success of Data Services relies upon the greater research community using the approach as the primary method for accessing evidence-based data. If the tools and technology utilized become outdated or fail to offer advanced features available via other methods, the approach will lose viability due to non-use.    Staying abreast of technological improvements in advance of the development of risk factors will naturally be critical to the success of the program. An inherent danger is that the owning organization will wait too long to recognize and affirm the requirement to upgrade or refresh their technology.   3.   Which frameworks, policies, practices, or methods show promise in overcoming challenges experienced by governments in their evidence building?   Preventative system maintenance and fair metadata practices can build lawmakers confidence in implementing evidence-based data sharing. A structured and well-architected Data Services approach is required to successfully implement sharing of evidence-based data across the Federal research space. Recent and rapid advancements in associated technologies and methods have made such feats not only possible, but increasingly efficient, significantly expanding the capabilities and subsequent value of enterprise data management and analysis.   The irony, however, is that this same march of progress can also jeopardize the justification for the systems as they are at risk of being outpaced, marginalized, or rendered obsolete. Assessment is perceived as costly up front and therefore rarely maintained as a high priority. However, delays often lead to more expensive remediation or rushed decisions driven by urgent need rather than thoughtful improvement. Left unaddressed, future issues can compound into greater technical debt, reduced sustainability, and challenges that can quickly become insurmountable without disproportionate additional cost. Organizational culture has been framed as the foundation for any innovative technology to gain successful traction (Harvard Business Review, 2020).  Therefore, our additional recommendation is to establish procedures for regular and consistent technology assessment as an established practice to identify opportunities for improvement. This can be accomplished in several diverse ways, including adding this responsibility to an existing role or creating semi-regular personnel to complete these tasks. The key will be to put in place a    regular schedule to review existing and evolving needs, technology, and environment to identify any issues or deficiencies in both the current and future context, prompting a review of new opportunities for potential improvement.   4.   The Commission on Evidence-Based Policymaking (See: www.cep.gov) recommended the creation of a National Secure Data Service (See Commission Report at www.cep.gov). Do you agree with this recommendation, and if so, what should be the essential features of a National Secure Data Service?  As a member of the Data Coalition, Rotunda Solutions strongly supports the assessment provided in their report Modernizing U.S. Data Infrastructure: Design Consideration for Implementing a National Secure Data Service to Improve Statistics and Evidence Building. Creation of a National Secure Data Service holds excellent value and aligns well with United States priorities to remain at the forefront of thought leadership, advancement, capability, and achievement in science and technology. Accordingly, we recommend four criteria for achieving data excellence: data integrity, data literacy, data accessibility, and data implementation. Each criterion provides concrete suggestions for how the Data Service can achieve excellence gleaned from experience in industry.  Data Integrity   Authentication, Authorization & Accounting (AAA) o Data harnessed for policy support must be auditable. Authorized users should be  able to see where the data came from, who performed any create, read, update, or delete (CRUD) operations on the data, and why.   Hashing o To ensure that data has not been compromised, hashing algorithms should be used  to verify its authenticity.   Backups o In keeping with the 3-2-1 Principle, all data should have 3 copies, 2 on-site and 1  off-site.  Data Literacy   Datasets used for creating policy should be accompanied with thorough explanations, including the tools, settings, and methods used to obtain the data. This ensures that the data can be replicated by another party. Reproducibility is a vital component of data integrity.   It is crucial for policy makers to ensure the above, but data literacy is a responsibility that is shared, and not necessarily shouldered by the policy makers alone.  Organizations with supportive infrastructures and well-defined roles can spread the responsibility across a mixture of those who have the positioning and ability to achieve and maintain a high level of data literacy and expertise. This ensures that expectations are reasonable without sacrificing intellectual capital.      Several Commercial Off-the-Shelf (COTS) and Free and Open-Source (FOSS) software and hardware solutions exist for creating visualizations and summaries of data.   Some to consider are included below: o Elastic Canvas: Apache backs Elastic Canvas. o Grafana o Hybrid Open-Source Software (HOSS)  Data Accessibility    Current solutions have been partially implemented, such as Data.gov. However, such sites are merely collections of several other repositories from independent organizations. Some of these cannot be reached without proper access with the individual organization. An example of government site integration with data visualization tools that enable further data accessibility are Data.gov’s integration with Plot.ly and CartoDB.   Government organizations have variable methods of participation with the Data.gov repository. Some organizations may provide an up-to-date, accessible CSV files, or APIs (Application Programming Interfaces), while others may provide difficult to wrangle data in PDFs (Portable Document Formats), data that is rife with missing variables, lacking in variable clarity, and/or infrequently (or never) updated.  Data Implementation   For any drafts of evidence-based policy, policy makers ought to provide a way for the authors of the evidence & the public (who have access to the data) to provide comments & concerns before it is completed.  Information Governance    Though the terms are often used interchangeably, there is value in drawing a distinction between data and information. They are certainly interrelated: Data is seen as a raw precursor, while information is data that has been organized and given context. One of the primary purposes of the Data Services program is to provide improved access to evidence-based data to allow more users to generate better information through analysis.   The significant risk that users will misuse, mishandle, or misinterpret data creates a vulnerability that datasets will be used to draw invalid and unjustified information. This is especially true in the current climate with the proliferation of social media and click-bait headlines.  o We have seen recent examples of this occurring during the release of data related to the COVID-19 pandemic. Raw data related to cases, hospitalizations, and deaths were made available to the public early in the spread of the virus, but with little guidance regarding the way the data was being collected, the context in which the data should be assessed, and the proper way to relate that data to other data sources.    This led to many avoidable erroneous conclusions, misleading articles, and conspiracy theory videos. Additionally, once these examples of faulty information based upon the data were being presented to the public, the managers of the COVID data were slow to respond to or clarify the issues.   o This illustrates the need for Information Governance. Like Data Governance,  Information Governance involves the management of both the development of and value derived from information based upon the data. In this case, Information Governance would take two forms – developmental and responsive.   Developmental information governance would involve the management of how information is derived from the evidence-based data. Controlling how users create information out of raw data across all data sources spanning the breadth of the research space would not only be impractical, but it would also impose unwarranted restrictions on scientific inquiry. Certainly, no one would want a governance organization to dictate and limit how data can be utilized to gain insights. Guidelines can be provided to end users accessing the data so that necessary context is not overlooked.  o This can be implemented in the form of guidelines documents tied to Service Level Agreements and can be incorporated with usage of metadata from a metadata repository, which would be the source for the contextual information. Outlining guidelines up front will provide structure to manage the information outputs and provide a foundation to enable iterative methods of ensuring authenticity and integrity provide a means to ensure their authenticity and integrity. They can also be used to help ensure that resultant information conforms to the same legal and regulatory vigor as the original data.   Responsive information governance would involve the establishment of the means to identify and respond to circumstances where data is used improperly. It is inevitable that, if data is being made available to a broad spectrum of researchers to drive new and varied lines of inquiry, that at some point the data will be misused. And it is even more certain that if the data becomes publicly available, news organizations, politicians, and other influencers will be quick to draw conclusions, even if incorrect, and spread those to large audiences. It behooves any governmental body tasked with the responsibility of providing access to data to also be tasked with promptly responding to the incorrect usage of that data.   o This can be accomplished by establishing an Information Governance Council consisting of both representative(s) with knowledge and understanding of the data, as well as experts in areas such as governmental compliance, research practices, and public relations. Policy and process documents in support of Information Governance can also be generated and published.      Information Governance can provide both protection against the misuse of evidence-based data as well as the framework which will help researchers and other users from wasted efforts due to a lack of understanding of the source data.    6.   If  created,  how  should  a  data  service  be  structured  to  best  facilitate  (1)  research  and development of secure data access and confidentiality technologies and methods, (2) and agency adoption of those technologies and techniques?   Applying a Data Services approach to facilitate use and analysis of evidence-based data will allow for the flexibility to rapidly provide a wide array of data to researchers with minimal development and infrastructure. However, even if data is not hosted in a central repository the Data Service will still need to provide sufficient information about available datasets for users to assess if a particular dataset merits additional study. Managing the vast array of data through the Data Services will be challenging. Keeping track of all the various data elements being collected by researchers and understanding how that data interrelates is crucial to being able to properly understand and use the data. The recommendation in Part Four is therefore to develop and maintain a metadata repository.   Metadata is defined as “data about data.” Without reliable metadata, it will be impossible to know what data is available, where it originates, how it moves through systems, who has access to it, and what it means for the data to be high quality. Moreover, it is critical for metadata standards to be shared across organizations that will be involved in data sharing.  We recommend the creation of a central repository to collect the metadata for all the sources connected to the Data Services. This will address several issues: Data Awareness, Data Quality, Technical Data, Security, and Context.   1. Data Awareness: A metadata catalog will store information about the definitions and usage of data elements. This information will be invaluable for researchers looking to discover added sources of data and finding specific data entities which will be useful.   2. Data Quality: Supplying data quality rules will aid Data Stewards in ensuring that data quality still is consistent when being accessed by such a wide variety of users.  3. Technical Data: Full information about the technical data, such as the physical database table and column names, column properties, and models, will allow users to have necessary information to connect to the source systems and properly and more efficiently code ETL (Extract Transform Load) processes.  4. Security: Understanding the security rules and allowable access will enable stewards and users to understand the restrictions that apply to the source data.     5. Context: Metadata can capture all other pertinent information that will supply context for stewards to manage the data and for users to access it, including data lineage, update schedules, value constraints and known issues.   Failure to address the need for comprehensive metadata to support the Data Services approach will open the program to several significant risks. Allowing a wide spectrum of users to connect to many different evidence-based data sources could quickly lead to a complete failure of data management leading to a Data Service that is unused despite significant investments because users do not understand what is being provided well enough to trust available data is accurate, reliable, or timely. Additionally, without a full catalog of metadata to provide context and reference information to guide users, there is a danger that users will not accept the approach as a valid means of accessing reference data.   9.   What are the key problems and use cases where collaborative work between federal, state, and local authorities’ data analysis can inform decisions? What are key decision support tools? How would greater communication about data and tools benefit expanded evidence building? Infrastructure for Meeting Public and Evidence Building Needs –10. What basic public data services are essential for a data service to address existing capacity gaps and needs? What infrastructure or incentives can the federal government create that locals and states cannot?  The creation of a federal data service provides a unique opportunity to understand and expand the use of data for decision making at the state, local, and Federal level. Use-statistics for the supply and demand of data outside existing data silos could be leveraged to map the network of data providers, datasets, and data users (both researchers and lawmakers). This network map would offer a wealth of information about data curation and consumption, providing guidance for questions posed by the report from The Data Foundation, including:    How should a data service prioritize initial project approvals?  How can a data service ensure continued collaboration for researchers and agencies?  What processes should be considered to enable data discovery and data integration?  How should user feedback be routinely incorporated?  What are the most efficient processes for improving data quality in government datasets  once users identify potential issues?   Basic implementation:    1. Uniquely identify datasets, dataset providers and data users 2. Identify and track keywords for datasets, dataset providers, and data users.  3. Capture dataset download/search instances. 4. Track which organizations/individuals downloaded/searched for which datasets.     5. Track which datasets are used (downloaded or searched for) together. 6. Use this information to build a network map connecting data providers, datasets, and data  users.   Possible analyses from network map use statistics:   1. Identification of priority datasets through user-demand assessment  a. Metrics  b. Measurement - assessing demand can inform data exploration efforts by identifying  areas/types of datasets that are likely to be high value for data users. c. User demand can be used to identify which datasets should be priority for initial  implementation and which merit further development. 2. Aligning organizational requirements, project proposals, and project outcomes.   a. Identifying common data pathways (pairing between data providers and data users)  b. Identifying areas for potential collaboration between data users and providers. c. Providing avenues for feedback regarding data collection modifications or quality  improvements to increase dataset utility. 3. Clustering datasets by similarity   a. Clustering datasets by similarity could help identify duplicative collection efforts. b. Clustering datasets commonly used/searched together could provide the foundation  for a dataset recommender engine. c. Clustering busy datasets or dataset keywords downloaded/searched for helps  identify organizations that may have interest in forming user groups.   References  Dijkstra, Edsger W. (18 June 1975). "How do we tell truths that might hurt?". University of Texas at Austin. EWD498. Archived from the original on 2 May 2017. Retrieved 09 February 2021.   Federal agencies’ reliance on outdated and unsupported information technology: A ticking time bomb. (2016.). Retrieved February 8, United States House Committee on Oversight and Government Reform. 2021, from https://republicans-oversight.house.gov/hearing/federal-agencies-reliance-on-outdated-and-unsupported-information-technology-a-ticking-time-bomb/  Why do your employees resist new tech? (2020, August 21). Harvard Business Review. https://hbr.org/2020/08/why-do-your-employees-resist-new-tech           Data Ethics Embodied in Practice A Framework for Synthesizing and Applying Federal Data Ethics Principles     Date:  February 9, 2021  Electronic submission   1. Introduction  A data ethics framework is a critical component of a responsible data ecosystem, addressing  subjects that include privacy, transparency, trust, ownership, governance, consent, fair use, bias,  disinformation, and weaponization, as applied to techniques and standards for storage,  management, and applications. Rotunda Solutions applauds the Advisory Committee on Data for  Evidence Building for their leadership and foresight in addressing the topics in its examination of  evidence-based policymaking. Providing clear data ethics principles independent of prescriptive  methods is a challenge for which our team is uniquely suited. We are familiar with the technical  and theoretical principles that are behind each stage of the data management pipeline and can  advise broadly while providing clarity for unique issues that arise during individual case studies.   The following comments seek to recommend practices and frameworks that show promise in  establishing a Data Ethics Framework to improve vital data protections, identify and mitigate key  risks, and facilitate responsible and cohesive data sharing across pressing needs at the Federal,  state, and local level.            Our approach, properly applied, will satisfy three essential ethical principles for data:  1. Respect for Persons: People are treated with respect for dignity and autonomy.  2. Beneficence: First, do not harm; Second, maximize benefits; Third, minimize harms.  3. Justice: People are treated fairly and equitably.   2. Proposal   Foremost, we propose researching and identifying commonalities in requirements, risks, and  usage models to inform a structuring of standards, to be deemed Data Ethics Embodied in  Practice (DEEP). The intention of DEEP is to create shared standards for groups that require  individual implementation strategies while continually embodying Federal data ethics principles.  Strategically developed common standards reduce reliance on over-governance while enabling  the flexibility required for innovation and effective application across a wide variety of  stakeholders and contexts.    Furthermore, data is a continually evolving entity, and the priorities of Federal entities shift over  time. It is necessary to avoid overly specific technical language and instead focus on the ethical  principles that should drive decision-making. The intent is to standardize to a minimum level and  avoid over-governance. Common standards are critically beneficial, and we recognize that  organizations need to dynamically grow and develop individual implementations unique to their  context. This is a dynamic and continuous process which can be guided by best practices and  recommendations to ensure cohesiveness and quality, while acknowledging that the profiles,  needs, and unique priorities of Federal entities greatly and change over time.            We are prepared to make recommendations for data handling, management, and application  practices based upon the principles of (1) Respect for Persons, (2) Beneficence, and (3) Justice.  Despite the proliferation of automatizing capacities within data engineering and data science,  humans still play a significant role from study design to legislation action following data-driven  changes in policy. Data is no longer a silo, but instead proliferates through all departments and  aspects of government and society.    As our societies grow increasingly diverse, so must the change-makers that serve them. Diversity  of talent has myriad benefits, including ensuring that multiple perspectives and outcomes are  considered during data management risk management evaluations. The culture of a department  matters. Well-skilled scientists and engineers from diverse socioeconomic, gender, racial,  religious, ability, and cultural backgrounds are integral to success. Studies have shown that  companies with higher levels of ethnic and gender diversity financially outperform those with  lower levels (McKinsey 2020). Throughout history, the government has not always acted in the  best interests of minority populations. This elevates the importance of data ethics, an area where  leaders can address the infrastructure changes that serve elevate trust and build progress. From  data collection to data applications, building a foundation to earn public is critical. To make  these changes effectively, it is important to incorporate the historical perspectives of people for  whom science and technology may have wronged throughout United States history.   Moreover, high profile data breaches have led to widespread distrust in public discourse. In a  2016 survey of 1,040 adults, the Pew Research Foundation found that 28 percent of people  surveyed had no confidence whatsoever that the Federal Government could protect their personal          data (Smith, 2017). Making reparations for these disruptions in the foundational tenants of civic  trust requires a foundational shift in mentality prior to the development of technical adaptations,  which will help ensure that adaptations remain relevant, obtain compliance, and demonstrate a  shared ethos.    The Federal Government has struggled to retain talent, as mentioned in the Virtual Public  Plenary Conference for the National Security Commission on Artificial Intelligence (NSCAI) in  January of 2021. Moreover, the Federal Government lags industry in a variety of diversity  metrics. Respect, Beneficence and Justice can be served by ensuring fair representation of  leadership in organizations that manage and disseminate Federal data.   3. Case Studies  Below, we provide a case study that is illustrative of the importance of underlying data ethics  frameworks with common standards that can proliferate across agencies. This example  exemplifies the importance of contrasting the ideologies and applications across multiple  agencies. There needs to be flexibility and freedom to evolve standards based upon guidelines.  Use-cases will be unique, and so a Federal data ethics framework is not necessarily prescriptive,  but it is a common groundwork for Federal government to build upon. This enables transference.            FEDERAL AGENCY DATA PRIORITIES  DEPARTMENT Department of Defense Department of Education  DATA UTILIZATION High Consumer, Low Provider High Provider  SECURITY PRIORITY National Security Child Privacy  CHALLENGE? Expectations of public and Congressional accountability and transparency often compete with protecting information from both a competitive and security standpoint. There is a struggle to balance internal and external risks and protections.  Collecting data and responsibly reporting accurate data from a multitude of different schools and districts, with lack of standardization of data, formats, and procedures; frequency of errors; and large variance in compliance and timeliness, while addressing privacy, bias, applicability in context, and execution gaps  ETHOS The DoD (Department of Defense) asserts that FOIA will be upheld in both letter and spirit from a data security standpoint. The security of a weapons system is a priority from a national security standpoint, which informs the development of security standards.  The Department of Education endeavors to maintain anonymity at the individual level, but is required to publish larger demographic, resourcing, and performance data for both public and regulatory consumption.  READINESS The Departments of Defense and Education have vastly different states of readiness, operational tempos, accountability, stakeholders, and levels of maturity in distinct aspects of data operations, including general understanding, organizational adoption, data collection, enterprise data management, data analysis, data ethics, and end usage. Where one may serve its needs with very sophisticated and robust structures within enclaves, while acknowledging limited coordination, another may have benefit from more shallow but widespread and integrated interagency sharing. The realities are very different, and priorities of greatest value to one context may not be shared in another.             As one can deduce from the above example, identical data standards cannot be enacted and  adopted across entire Federal government. We propose that we identify and classify a  representative subpopulation of Federal groups to consider in the development of a Federal  policy. It is important to consider multiple stakeholder groups in the development of a Federal  policy.   4. Best Practices  To develop a thorough set of best practices that can apply across multiple agencies, we must  address the following questions:   How do their missions and their need for protections inform their data usage behavior and priorities?    Who are the stakeholder groups? What are their associations and value statements?  What are they trying to achieve?   o Within these stakeholder populations, what is the need/justification to access the data? What considerations exist? How do roles which range from disparate to overlapping and interconnected raise unique ethical questions and scenarios?  i. Examples of “need to know” vs “FOUO” [document designation, not classification] vs clearance vs chain of command:  ii. Ethical quandaries that arise in DoD, for instance: 1. https://resources.data.gov/assets/documents/fds-data-ethics- framework.pdf  Are these unique to DoD (Department of Defense) or is there an analog in other orgs? Is there a common standard that helps us to synthesize a definitive answer to these problems?   2. If not, are there guidelines that can be universally prescribed for the approach?   What are the risks that need to be considered when merging datasets from groups with discordant data standards?  o I.e., What happens if HHS (Health and Human Services) (Health and Human Services) data, which fiercely prioritizes privacy, is combined with IRS data, Census data, and law enforcement data? In aggregate, this may reveal insights that fundamentally violate the intent of the component data sources.  o Is there an argument for prioritization of conflicting organizational ethical standards by need? By mission? By association?           How should server prioritization operate? What are the ethical considerations in prioritizing access?    How can we manage threats to data integrity?  o It is not always brute force hacking that we must contend with; it can be minor  technical changes that proliferate into eventual loss of integrity in multiple datasets.   o Do we define preservation of data integrity as an ethical imperative in and of itself?   o Is there an ethical obligation on the part of the organization that serves up the data?   o Is the burden on the user/consumer of the data to do their due diligence to gauge data trustworthiness?   Identification of the commonalities across groups can help mitigate over-governance and over- regulation. Data ethics is not a process that can occur in a silo. Just as technological development  is an iterative process, data ethics must occur concurrently with technical developments. Below,  we propose four major components that comprise the data lifecycle process and outline key  components to inform corresponding ethics principles.   5. Key Concepts  The ethics of handling data are complex, but can be successfully addressed by focusing on two  key concepts:  i. Impact on people: Because data stores personal data and is used to make decisions that  impact the lives of people, it is important to carefully manage its quality and reliability.  ii. Potential for misuse: Misusing data can have detrimental effects on people, programs, and  organizations, creating a moral imperative to prevent it.            6. Data Ethics Embodied in Practice (DEEP): Four Points Overview  Data ethics involves a thorough interrogation of the data lifecycle, which involves collection,  storage, management, and applications. As data begets more data, it is necessary to continually  revisit compliance with ethics standards. For example, a dataset that begins as child enrollment in  a new STEM academy may be classified as anonymized when viewed alone. However, if a new  dataset is compiled based on the previous study, and attempts to reconcile income classifications  by zip code, an even finer granularity of demographics, or enrollment and success metrics, a  portion of those protections may be jeopardized. This could risk exposing a child’s identity,  regardless of the intent or policies of each component data set in isolation.    The pace of technological advancements is itself a risk. It is common knowledge that personal  identifiers such as names are no longer necessary for accurate identification. As two decades ago,  it was postulated that over half of the U.S. population were at risk of being identified uniquely by  only location, gender, and date-of-birth (Sweeney L., 2000). Since that time, we have only seen a  decrease in data privacy and an exponential increase in new sources of high-risk data, including  efflux of smartphone utilization. and the products of commercial and data mining efforts.   Thus, the problem is not only difficult to handle, but also, a challenge to anticipate or diagnose,  especially when data is merged in increasingly complex ways from multiple, independently- managed, uncoordinated, and dynamic sources. This is true even when said systems faithfully  follow basic standards. Continuous, vigilant, and informed diligence is necessary to maintain  sustained and effective guidance, more so responsible usage. As a member of the Data Coalition,  this is particularly important to the values of our firm. We agree with the recommendations          provided in their report Modernizing U.S. Data Infrastructure: Design Consideration for  Implementing a National Secure Data Service to Improve Statistics and Evidence Building, and  understand that such a system shoulders numerous responsibilities, many of which fall under the  consideration of Data Ethics and can be addressed by the due diligence we recommend in this  document.   The Data Ethics Tenets as defined by the Federal Data Ethics team were instated to support users  of Federal data to make ethical and accountable decisions throughout the life cycle of data  acquisition, processing, dissemination, and usage, storage, and disposal.    The Federal Data Strategy 2020 Action Plan asserted that Federal leaders should promote a data  ethics-driven culture by showing strong leadership by example. In brief, the Data Ethics Tenets  are: 1 - Uphold applicable statutes, regulations, professional practices, and ethical standards.  Existing laws reflect and reinforce ethics. 2 - Respect the public, individuals, and communities. 3  - Respect privacy and confidentiality. Data activities involving individual privacy should align  with the Fair Information Practice Principles (FIPPs). 4 - Act with honesty, integrity, and humility.  5 - Hold oneself and others accountable. 6 - Promote transparency. 7 - Stay informed of  developments in the fields of data management and data science.   In the report, it is specified that the Federal Data Ethics Framework is a “living” resource and to  be updated by the CDO (Chief Data Officer) Council and ICSP every 24 months (about 2 years).  Our data ethics principles are intended to support the seven tenants promoted by the Federal Data  Strategy 2020 Action Plan and intended to assist in translating theory into practice.           Point One: Collection  i. Corresponding Federal Data Ethics Tenants*: 2, 3, 5, 6  ii. Collection should be informed by a clear set of principles that are directly linked to data  usage. This is wise from a personal identifiable information (PII) security standpoint and  minimizes risks associated with a worst-case scenario data breach.  iii. Make a clear delineation between data collected for grant-review purposes and data  collected for statistical research purposes.   iv. Stakeholder groups should be clearly identified, and priorities defined within the initial  data management plan. To mitigate complications arising from competing priorities, use- cases should be reviewed by leadership across organizations.  Point Two: Storage  i. Corresponding Federal Data Ethics Tenants: 1, 2, 3, 5  ii. Principle of least permissions should be designated in an initial systems diagram.  Engineers, I.T. experts, developers and data scientists should meet regularly with  leadership to ensure that systems permissions are closely aligned with mission goals.  Systems diagrams should be continually refreshed, as necessary.  iii. Sever prioritization should be allocated on a priority-basis as designated by leadership from  multiple government organizations to assist with the reconciling of potential competing  priorities.  iv. Threats to data integrity can be managed through a continual review of dataset access and  security classification changes that may occur upon the compounding of datapoints.            Point Three: Management  i. Corresponding Federal Data Ethics Tenants: 1, 2, 3, 4, 5  ii. Datasets should be reviewed individually and in tandem for security compliance. Continual  reviews are necessary to avoid breaches of personal information that could result upon the  specific combination of datapoints.   iii. Security classifications should be closely aligned to dataset classification to promote  collaboration and open-source data whenever possible.  iv. Define appropriate and accessible formats to promote public use when possible. Open data  vs accessible data vs consumable data vs understandable data. Define the Federal  obligation to its populace in this regard.  Point Four: Applications  i. Corresponding Federal Data Ethics Tenants: 5, 6, 7  ii. Applications should be continually reviewed for alignment with original use-cases to  promote public trust and professional accountability.  iii. Opportunities for novel applications should be identified through interdisciplinary  collaborative meetings to occur to at regular intervals.   iv. Consider hosting an unclassified briefing on YouTube or other public forum that would  enable live streaming and public interaction.   As defined in the Federal Data Ethics report, benefits of the Data Ethics framework include:  Consistency, Better Data-Driven Decisions, Risk Mitigation, Increased Transparency,  Consideration of Wider Perspectives, and Improved Public Trust.            The Federal Data Strategy (FDS) describes a 10–year vision for how the Federal Government will  accelerate the use of data to deliver on mission, serve the public, and steward resources while  protecting security, privacy, and confidentiality. The strategy was developed to guide Federal data  management and use via a mission statement, ten operating principles, and a set of 40 best practices  to guide agencies in leveraging the value of Federal and federally sponsored data. Principles  designated by the FDS were as follows: Ethical Governance, Conscious Design, and Learning  Culture. Practices designated by the FDS fall under the following three categories: (1) Building a  Culture that Values Data and Promotes Public Use, (2) Governing, Managing and Protecting Data,  and (3) Promoting Efficient and Appropriate Data Use. The creation of guidelines to promote  interagency adherence to the wide array of theoretical and practical guidance provided by  government entities is critical to ensure that security and ethics are continually calibrated to ensure  safety while promoting growth. Simplified, real-world guidelines are critical to promoting  compliance and continual engagement with ethics standards as data sets and organizational  priorities evolve.    At its core, establishing, adopting, and embodying a strong data ethics framework is about building  trust. The organizational, end user, and public trust necessary for the success of an evidence-based  system extends beyond just the veracity and reliability of the data itself. We must endeavor to build  faith in the associated technologies, sources, systems, owners, managers, leaders, agendas, and  safeguards. By supporting initiatives that seek shared standards, transparency, and fundamental  understanding of both the data and the human relationship to data, we are taking steps in the right  direction.            References  Action plan—Federal Data Strategy. Retrieved February 2, 2021, from https://strategy.data.gov/assets/docs/2020-federal-data-strategy-action-plan.pdf  Federal Data Strategy - Data Ethics Framework. Retrieved February 2, 2021 from https://resources.data.gov/assets/documents/fds-data-ethics-framework.pdf   L. Sweeney Simple Demographics Often Identify People Uniquely. Carnegie Mellon University, Data Privacy Working Paper 3. Pittsburgh 2000. (PDF).  Diversity Wins: How Inclusion Matters | McKinsey. May 2020. Retrieved February 3, 2021, from https://www.mckinsey.com/featured-insights/diversity-and-inclusion/diversity-wins-how-inclusion-matters#  NSCAI Plenary—Day 1—January 25, 2021. Retrieved February 3, 2021, from https://www.youtube.com/watch?v=gov6_qWxWsQ  Smith, A. M. (2017, January 26). Americans and cybersecurity. Pew Research Center: Internet, Science & Tech. https://www.pewresearch.org/internet/2017/01/26/americans-and-cybersecurity/    *All tenants are intended to be upheld within DEEP. Specific tenants were underscored for relevance to the subtopic.     